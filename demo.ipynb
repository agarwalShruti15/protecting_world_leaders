{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "\n",
    "This notebook is to show how to generate OpenFace annotated videos and plot two facial movements for a segment of the video for analysis.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "<ul>\n",
    "    <li> Path to OpenFace2.0 build/bin folder. This folder is created after OpenFace compilation. Please follow the instructions given <a href=\"https://github.com/TadasBaltrusaitis/OpenFace/wiki\">here</a> to compile OpenFace2.0 on your machine.\n",
    "    <li> Path to input video. \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import os\n",
    "import utils as u\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "open_face_path = 'OpenFace' #path to build/bin folder of OpenFace2.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the demo annotated videos\n",
    "\n",
    "This is a small utility to store the OpenFace2.0 annotated videos. A list of video files are given video_names and the annotated videos are stored at the path out_fldr with the same names in .mp4 format. This function ensures the outfolder doesn't store the csv or extra files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fldr = 'demo/annotated' #save the annotated videos\n",
    "#vid_fldr = 'test_ex'\n",
    "#video_names = [os.path.join(vid_fldr, f) for f in os.listdir(vid_fldr) if f.endswith('.mp4')] #\n",
    "video_names = ['test_ex/-kjyltrKZSY_3.mp4'] \n",
    "\n",
    "print(video_names)\n",
    "for v in range(len(video_names)):\n",
    "    u.out_tracked_video(video_names[v], out_fldr, open_face_path)\n",
    "    clear_output(wait=True)\n",
    "    print('{}/{}: {}'.format(v, len(video_names), video_names[v]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the video with correlation pairs\n",
    "\n",
    "Utility to save the a single correlation pair in a video segment. The video segment should be given in range of frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [0, -1] #enitre video segment, or the start and end frame\n",
    "avg_len = 300 #the number of frames to average for a smooth signal\n",
    "c_t = 0.93 #the confidence threshold for OpenFace detection. Even a single less confident frame will reject the entire 10-second clip\n",
    "\n",
    "#OBAMA\n",
    "bo_dict = {'video_nm': 'test_ex/obama-lipsync.mp4', \n",
    "           'out_fldr': 'demo/obama_corr', \n",
    "           'comb': [' AU15_r', 'lip_hor']}\n",
    "\n",
    "#TRUMP\n",
    "dt_dict = {'video_nm': 'test_ex/trump-real.mp4', \n",
    "           'out_fldr': 'demo/trump_corr', \n",
    "           'comb': [' AU17_r', ' AU14_r']}\n",
    "\n",
    "#SANDERS\n",
    "bs_dict = {'video_nm': 'test_ex/sanders-faceswap2.mp4', \n",
    "           'out_fldr': 'demo/sanders_corr', \n",
    "           'comb': [' AU06_r', ' AU12_r']}\n",
    "#CLINTON\n",
    "hc_dict = {'video_nm': 'test_ex/clinton-faceswap.mp4', \n",
    "           'out_fldr': 'demo/clinton_corr', \n",
    "           'comb': [' AU06_r', ' AU15_r']}\n",
    "#WARREN\n",
    "ew_dict = {'video_nm': 'test_ex/warren-faceswap.mp4', \n",
    "           'out_fldr': 'demo/warren_corr', \n",
    "           'comb': [' AU06_r', ' pose_Rx']}\n",
    "\n",
    "param_dict = dt_dict #assign the params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(param_dict['out_fldr'], exist_ok = True)\n",
    "\n",
    "#get the facial features\n",
    "csv_features = u.get_facial_features(param_dict['video_nm'], open_face_path, conf_thres=c_t) # we need less rejection\n",
    "\n",
    "#plot the facial features for the combination of features\n",
    "u.save_corr_video(param_dict['video_nm'], csv_features, param_dict['comb'], t, avg_len, \n",
    "                  param_dict['out_fldr'], y_lims=(-0.5, 0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
